{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotion Analysis",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGidy_-IGmax"
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import PorterStemmer\n",
        "import numpy as np"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3oDSK9ZPxOG",
        "outputId": "4f0bdd59-71b4-434f-db8e-564ce4d7580d"
      },
      "source": [
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6pOpjdCHM5-"
      },
      "source": [
        "def data_reader(name):\n",
        "  data = pd.read_csv(name, sep=\";\", header=None)\n",
        "  data.columns = [\"text\", \"emotion\"]\n",
        "  return data"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW-YWE4YFbDl"
      },
      "source": [
        "train = data_reader('train.txt')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "xwypK2mHGu_J",
        "outputId": "77ff587f-39e4-4dfb-8c39-3a79748644e4"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  emotion\n",
              "0                            i didnt feel humiliated  sadness\n",
              "1  i can go from feeling so hopeless to so damned...  sadness\n",
              "2   im grabbing a minute to post i feel greedy wrong    anger\n",
              "3  i am ever feeling nostalgic about the fireplac...     love\n",
              "4                               i am feeling grouchy    anger"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIEb3j2bIaPN"
      },
      "source": [
        "classes = train.emotion.unique()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltb2V730Tl2q"
      },
      "source": [
        "classes_token = {classes[i]:i for i in range(len(classes))}"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdRXAbvmIaFZ"
      },
      "source": [
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "ps = PorterStemmer()\n",
        "\n",
        "sentences = []\n",
        "for item in train.values:\n",
        "  sentence = item[0].lower()\n",
        "  word_tokens = tokenizer.tokenize(sentence)\n",
        "  filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "  stemmed = [ps.stem(w) for w in word_tokens]\n",
        "  sentences.append([stemmed, item[1]])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpMnwwv4IZ_0"
      },
      "source": [
        "vocabulary = []\n",
        "\n",
        "for item in sentences:\n",
        "    for word in item[0]:\n",
        "      vocabulary.append(word)\n",
        "\n",
        "vocabulary = set(vocabulary)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTjjXr-tIZ9F",
        "outputId": "90711bc4-d1d8-480f-eecc-c8b879d1a194"
      },
      "source": [
        "len(vocabulary)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11123"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvvgXmlRIZ6W"
      },
      "source": [
        "vocab_classes = {word:[0, 0, 0, 0, 0, 0] for word in vocabulary}"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSvMjwEeZuby"
      },
      "source": [
        "classes_len = {i:0 for i in classes}"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u983yNqOZ_0j",
        "outputId": "69425254-7d4e-4e2e-abb9-ca0d55a38aa8"
      },
      "source": [
        "classes_len"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'anger': 0, 'fear': 0, 'joy': 0, 'love': 0, 'sadness': 0, 'surprise': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdnZUyRfIZz5"
      },
      "source": [
        "for c, v in classes_token.items():\n",
        "  for item in sentences:\n",
        "    if item[1] == c:\n",
        "      for word in item[0]:\n",
        "        vocab_classes[word][v] += 1\n",
        "        classes_len[c] += 1"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8cjExEEcEWh"
      },
      "source": [
        "def sum_other_lens(cv, classes_len):\n",
        "  sum = 0\n",
        "  for c, v in classes_len.items():\n",
        "    if cv != v:\n",
        "      sum += classes_len[c]\n",
        "  return sum"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5hVR9rKchyv"
      },
      "source": [
        "other_lens = {c:sum_other_lens(v, classes_len) for c, v in classes_len.items()}"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ksx4YTqdXrv"
      },
      "source": [
        "def sum_word_occ_other_classes(word, cv):\n",
        "  sum = 0\n",
        "  for c, v in classes_len.items():\n",
        "    if cv != v:\n",
        "      sum += vocab_classes[word][classes_token[c]]\n",
        "  return sum"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vrs-vfad5Ry"
      },
      "source": [
        "probs = {word:[0, 0, 0, 0, 0, 0] for word in vocabulary}"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9W5Q6IskSHA"
      },
      "source": [
        "v_len = len(vocabulary)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LskNE8R9UCgT"
      },
      "source": [
        "for word in vocabulary:\n",
        "  for c, v in classes_token.items():\n",
        "    cc = (vocab_classes[word][v] + 1) / (classes_len[c] + v_len) \n",
        "    oc = (sum_word_occ_other_classes(word, v) + 1) / (other_lens[c] + v_len)\n",
        "    probs[word][v] = cc / oc"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El_fseW9UCZ0"
      },
      "source": [
        ""
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcFj13zKUCW9"
      },
      "source": [
        "def prob_calculator_for_one_class(c_name, sentence):\n",
        "  prior = classes_len[c_name] / other_lens[c_name]\n",
        "  mul = 1\n",
        "  for word in sentence:\n",
        "    if word in vocabulary:\n",
        "      mul *= probs[word][classes_token[c_name]]  \n",
        "  return mul*prior"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB5SHZNvgXc7"
      },
      "source": [
        "def preprocessing(sentence):\n",
        "  sentence = sentence.lower()\n",
        "  word_tokens = tokenizer.tokenize(sentence)\n",
        "  filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "  stemmed = [ps.stem(w) for w in word_tokens]\n",
        "  return stemmed"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXoV-j2EhYEZ"
      },
      "source": [
        "def argmax(current_probs):\n",
        "  max_v = -1\n",
        "  arg = ''\n",
        "  for c, v in current_probs.items():\n",
        "    if max_v < v:\n",
        "      max_v = v\n",
        "      arg = c\n",
        "  return arg"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIJfwn9QgXZi"
      },
      "source": [
        "def classifier(sentence):\n",
        "  current_probs = {classes[i]:0 for i in range(len(classes))}\n",
        "  sentence = preprocessing(sentence)\n",
        "  for c_name, c_value in classes_token.items():\n",
        "    c_p = prob_calculator_for_one_class(c_name, sentence)\n",
        "    current_probs[c_name] = c_p\n",
        "  return argmax(current_probs)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPuyT-XWgXWl"
      },
      "source": [
        "test = data_reader('test.txt')"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "oT2o7nAngXUA",
        "outputId": "f7e00562-ddb2-4a37-dd9e-bd230f5ac3cd"
      },
      "source": [
        "test"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im updating my blog because i feel shitty</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i never make her separate from me because i do...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i was feeling a little vain when i did this one</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>i just keep feeling like someone is being unki...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>im feeling a little cranky negative after this...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>i feel that i am useful to my people and that ...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>im feeling more comfortable with derby i feel ...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>i feel all weird when i have to meet w people ...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  emotion\n",
              "0     im feeling rather rotten so im not very ambiti...  sadness\n",
              "1             im updating my blog because i feel shitty  sadness\n",
              "2     i never make her separate from me because i do...  sadness\n",
              "3     i left with my bouquet of red and yellow tulip...      joy\n",
              "4       i was feeling a little vain when i did this one  sadness\n",
              "...                                                 ...      ...\n",
              "1995  i just keep feeling like someone is being unki...    anger\n",
              "1996  im feeling a little cranky negative after this...    anger\n",
              "1997  i feel that i am useful to my people and that ...      joy\n",
              "1998  im feeling more comfortable with derby i feel ...      joy\n",
              "1999  i feel all weird when i have to meet w people ...     fear\n",
              "\n",
              "[2000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsKiF53pqkAn"
      },
      "source": [
        "for item in test.values:\n",
        "  classified.append(classifier(item[0]))"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA68V7uLgXOY"
      },
      "source": [
        "classified = []\n",
        "all_corrects = 0\n",
        "for item in test.values:\n",
        "  p_c = classifier(item[0])\n",
        "  classified.append([item[0], p_c])\n",
        "  if p_c == item[1]:\n",
        "    all_corrects +=1\n",
        "\n",
        "accuracy = all_corrects / len(test.values)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahhVQC-wnOHl",
        "outputId": "ff5f4825-dca0-4121-8e7c-35b90635ad5c"
      },
      "source": [
        "print(accuracy)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VP9jbfNqg5n"
      },
      "source": [
        "output = pd.DataFrame(classified)\n",
        "output.columns = [\"text\", \"predicted_emotion\"]"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "fMaASVKOsGLM",
        "outputId": "8f1ed58d-5980-43c5-e0b7-9c7da27bb317"
      },
      "source": [
        "output.head()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>predicted_emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im updating my blog because i feel shitty</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i never make her separate from me because i do...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i was feeling a little vain when i did this one</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text predicted_emotion\n",
              "0  im feeling rather rotten so im not very ambiti...           sadness\n",
              "1          im updating my blog because i feel shitty           sadness\n",
              "2  i never make her separate from me because i do...             anger\n",
              "3  i left with my bouquet of red and yellow tulip...              fear\n",
              "4    i was feeling a little vain when i did this one           sadness"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ds3QQC5sRno"
      },
      "source": [
        "output.to_csv('output.csv', index=False)"
      ],
      "execution_count": 75,
      "outputs": []
    }
  ]
}